import logging
from typing import List, Union
from sentence_transformers import SentenceTransformer
import numpy as np

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EmbeddingModel:
    """
    Wrapper for SentenceTransformer to generate embeddings for product text.
    Uses 'all-MiniLM-L6-v2' by default which provides a good balance of speed and accuracy.
    """
    
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        """
        Initialize the embedding model.
        
        Args:
            model_name (str): Name of the model to load from HuggingFace.
        """
        self.model_name = model_name
        self.model = None
        self._load_model()

    def _load_model(self):
        """Loads the SentenceTransformer model, checking for local files first."""
        try:
            # 1. Try Local Path (Docker/Deploy friendly)
            # Assumes model_data is a sibling directory to the directory containing this script
            local_path = os.path.join(os.path.dirname(__file__), "..", "model_data", self.model_name)
            
            if os.path.exists(local_path):
                logger.info(f"Loading embedding model from local cache: {local_path}...")
                self.model = SentenceTransformer(local_path)
            else:
                 # 2. Fallback to Download (Will fail in offline Codespace if not cached)
                logger.info(f"Local model not found at {local_path}. Attempting to download: {self.model_name}...")
                self.model = SentenceTransformer(self.model_name)
            
            logger.info("Embedding model loaded successfully.")
        except Exception as e:
            logger.error(f"Failed to load embedding model {self.model_name}: {e}")
            raise e

    def embed_text(self, text: Union[str, List[str]]) -> Union[List[float], List[List[float]]]:
        """
        Generate embeddings for a string or list of strings.
        
        Args:
            text (str | List[str]): The text(s) to embed.
            
        Returns:
            List[float] | List[List[float]]: The embedding vector(s).
        """
        if not self.model:
            raise RuntimeError("Model not initialized. Call _load_model first.")

        if not text:
            logger.warning("Empty text provided for embedding.")
            return [] if isinstance(text, list) else []

        try:
            embeddings = self.model.encode(text)
            
            # Convert numpy array to list for easier handling/serialization
            if isinstance(embeddings, np.ndarray):
                return embeddings.tolist()
            
            return embeddings
        except Exception as e:
            logger.error(f"Error generating embeddings: {e}")
            raise e

    def get_dimension(self) -> int:
        """Returns the dimension of the embeddings generated by this model."""
        if not self.model:
            return 0
        return self.model.get_sentence_embedding_dimension()

if __name__ == "__main__":
    # Simple test
    try:
        embedder = EmbeddingModel()
        test_text = "SICK inductive proximity sensor with IO-Link"
        vector = embedder.embed_text(test_text)
        print(f"Generated embedding for '{test_text}'")
        print(f"Dimension: {len(vector)}")
        print(f"First 5 values: {vector[:5]}")
    except Exception as e:
        print(f"Test failed: {e}")
