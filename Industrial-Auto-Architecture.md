# Industrial Automation AI Recommendation System
## Complete Architecture & Implementation Guide

**Project:** AI-Powered Product Recommendation Engine for Industrial Automation  
**Client:** Alsakronline.com (WooCommerce)  
**Status:** MVP 1 Week | Production 1 Month  
**Date:** December 2025

---

## EXECUTIVE SUMMARY

This document outlines a complete, production-ready architecture for an AI-driven industrial automation product recommendation system integrated with WooCommerce. The system will:

- **Aggregate 100,000+ SKUs** from ABB, SICK, Siemens, Schneider Electric, Murrelektronik, and custom sources
- **Process queries** in < 5 seconds with confidence scoring and manufacturer citations
- **Support bidirectional communication** (English + Arabic) with tone adaptation
- **Enable smart purchasing journeys** with contact capture, upselling, and quotation workflows
- **Support multimodal input** (text, images, PDFs, datasheets)
- **Run on self-hosted infrastructure** (Hostinger Business) using free/open-source models
- **Comply with GDPR** and manufacturer IP requirements

---

## PART 1: COMPLETE END-TO-END ARCHITECTURE

### 1.1 System Overview Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         END-USER INTERFACES                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  WooCommerce Widget  â”‚   Web Chat Interface â”‚  Mobile Chat + Image Upload â”‚
â”‚  (Sidebar/Modal)     â”‚   (Standalone)       â”‚  (File: Sheet/PDF/Image)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                  â”‚                        â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   API GATEWAY / ROUTER     â”‚
                    â”‚  (Python FastAPI Server)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚                         â”‚
        â–¼                         â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TEXT QUERY      â”‚    â”‚  IMAGE/PDF       â”‚    â”‚  CONTACT & ORDER â”‚
â”‚  PROCESSOR       â”‚    â”‚  PROCESSOR       â”‚    â”‚  MANAGEMENT      â”‚
â”‚  (LLM Routing)   â”‚    â”‚  (Vision + OCR)  â”‚    â”‚  (Database)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   RAG ORCHESTRATOR    â”‚
                    â”‚  (LangChain Chain)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                        â”‚                        â”‚
        â–¼                        â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VECTOR DB       â”‚  â”‚  PRODUCT DATABASE â”‚  â”‚  LLM ENGINE      â”‚
â”‚  (Milvus/Weaviate)  â”‚  (PostgreSQL)     â”‚  â”‚  (Ollama/Llama2) â”‚
â”‚  Embeddings      â”‚  â”‚  100K+ SKUs      â”‚  â”‚  Open-Source     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                        â”‚                        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  RECOMMENDATION       â”‚
                    â”‚  ENGINE + RANKING     â”‚
                    â”‚  (Similarity + Logic) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                        â”‚                        â”‚
        â–¼                        â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RESPONSE        â”‚  â”‚  PURCHASING       â”‚  â”‚  WooCommerce     â”‚
â”‚  GENERATOR       â”‚  â”‚  JOURNEY HANDLER  â”‚  â”‚  API SYNC        â”‚
â”‚  (Multi-language)â”‚  â”‚  (CRM + Workflow) â”‚  â”‚  (Product Feed)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                        â”‚                        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   RESPONSE TO USER    â”‚
                    â”‚  (Chat + Purchase UI) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Technology Stack (Free & Open-Source)

| Layer | Component | Technology | Justification |
|-------|-----------|-----------|---------------|
| **Frontend** | Chat UI | React/Vue.js (custom) or Botpress Open-Source | Embedded in WooCommerce + multi-channel |
| **API Gateway** | REST/WebSocket Server | FastAPI (Python) | Fast, lightweight, free, easy deployment |
| **LLM Engine** | Language Model | Ollama + Llama2-7B or Mistral-7B | Self-hosted, free, 100K+ context |
| **Vector DB** | Semantic Search | Milvus (open-source) or Weaviate (free tier) | High-performance similarity search |
| **Data Storage** | Product Database | PostgreSQL + PostGIS | Free, robust, GDPR-compliant |
| **Document Processing** | OCR/Vision | Tesseract + OpenCV + BLIP | Image/PDF extraction, free alternatives |
| **Workflow Automation** | Contact/Order Flow | n8n (self-hosted free version) | Already familiar with n8n |
| **Hosting** | Server Runtime | Docker containers on Hostinger | Containerized, scalable |
| **Message Queue** | Async Tasks | Redis (free) | Handle async scraping/embedding |
| **Analytics** | Usage Tracking | Matomo (self-hosted, privacy-first) | GDPR-compliant analytics |

---

## PART 2: DETAILED STEP-BY-STEP IMPLEMENTATION ROADMAP

### PHASE 1: FOUNDATION & DATA (Days 1-3)

#### 1.1 Environment Setup
```bash
# SSH into Hostinger
ssh user@your-hostinger-server

# Create isolated environment
mkdir -p /home/automation-engine
cd /home/automation-engine

# Install Docker & Docker Compose
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Clone starter kit
git clone https://github.com/your-repo/industrial-automation-engine.git
cd industrial-automation-engine
```

#### 1.2 Data Ingestion Pipeline
**Goal:** Ingest 100K+ SKUs from multiple sources into a unified schema

**Data Sources to Integrate:**
- ABB: `https://new.abb.com/products` (web scraping)
- SICK: `https://www.sick.com/en-us/` (API or CSV)
- Siemens: Siemens Automation Configurator API
- Schneider Electric: `https://www.se.com/us/en/` (catalog)
- Murrelektronik: `https://www.murrelektronik.com/` (web scraping)
- Your internal CSV/JSON sources
- WooCommerce existing products

**Unified Data Model:**

```json
{
  "sku_id": "ABB-AC890-003-0007",
  "product_name": "ABB AC890 Microdrive Safety Control Unit",
  "manufacturer": "ABB",
  "category": ["Safety Systems", "Motion Control", "Drives"],
  "industry_use": ["Automotive", "Packaging", "General Manufacturing"],
  "specifications": {
    "voltage_input": "100-240V AC",
    "power_rating": "7.5kW",
    "ip_rating": "IP65",
    "certifications": ["CE", "UL", "ATEX"],
    "dimensions": "300x200x150mm",
    "weight_kg": 2.5,
    "technical_features": "Safe SIL3, PLd rated motion control"
  },
  "embedding_text": "ABB safety motor drive ATEX certified motion control...",
  "datasheet_url": "https://...",
  "datasheet_file": "abb_ac890_manual.pdf",
  "images": ["https://...", "https://..."],
  "pricing": {
    "cost_usd": 450,
    "wholesale_usd": 350,
    "available_in": ["Egypt", "UAE", "Saudi Arabia"]
  },
  "relationships": {
    "compatible_with": ["ABB-MC-100", "Siemens-SITOP-PSE"],
    "alternative_to": ["Schneider-Altivar-880"],
    "often_paired_with": ["SICK-S3000-Safety-PLC"]
  },
  "last_updated": "2025-12-13",
  "confidence_score": 0.95,
  "source": "abb_catalog_2025",
  "language": "en"
}
```

#### 1.3 Scraping & Data Collection Strategy

**Scraper Stack:**
```python
# tools/scrapers/industrial_scraper.py
from scrapy import Spider
from selenium import webdriver
from bs4 import BeautifulSoup
import json
import pandas as pd

class ABBScraper(Spider):
    """Scrapes ABB product catalog"""
    def parse(self, response):
        # Extract product data, save to staging DB
        pass

class SIEMENSScraper(Spider):
    """Scrapes Siemens products"""
    pass

class ManualDataImporter:
    """Handles CSV/JSON imports from partners"""
    def import_csv(self, file_path):
        df = pd.read_csv(file_path)
        # Map to unified schema
        return self.transform_to_schema(df)
```

**Deployment:**
- Run scrapers weekly via n8n workflows
- Store raw data in PostgreSQL `products_raw` table
- Transform via Python ETL pipeline to `products` table
- Sync embeddings to Milvus vector database

---

### PHASE 2: AI & SEARCH INFRASTRUCTURE (Days 3-5)

#### 2.1 Vector Database Setup (Milvus)

```yaml
# docker-compose.yml
version: '3.8'
services:
  milvus:
    image: milvusdb/milvus:v0.4.3
    ports:
      - "19530:19530"
    environment:
      COMMON_STORAGEPATH: /var/lib/milvus
    volumes:
      - ./milvus_data:/var/lib/milvus

  postgres:
    image: postgres:15
    ports:
      - "5432:5432"
    environment:
      POSTGRES_PASSWORD: secure_password
    volumes:
      - ./postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ./ollama_models:/root/.ollama
    command: serve
```

```bash
# Deploy
docker-compose up -d

# Verify services
curl http://localhost:19530/health
curl http://localhost:11434/api/tags
```

#### 2.2 Embedding & Indexing Pipeline

```python
# engine/embeddings/vector_indexer.py
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Milvus
import psycopg2
import json

class ProductVectorIndexer:
    def __init__(self):
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        self.vector_store = Milvus(
            embedding_function=self.embeddings,
            collection_name="industrial_products",
            connection_args={"host": "localhost", "port": 19530}
        )
    
    def index_products_batch(self, batch_size=100):
        """Index 100K products in batches"""
        conn = psycopg2.connect("dbname=automation_engine user=postgres")
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM products")
        total = cursor.fetchone()[0]
        
        for offset in range(0, total, batch_size):
            cursor.execute(
                """SELECT sku_id, product_name, specifications, 
                   embedding_text, datasheet_url, images, 
                   relationships FROM products LIMIT %s OFFSET %s""",
                (batch_size, offset)
            )
            products = cursor.fetchall()
            
            documents = [
                f"{p[1]} - {p[3]} - {json.dumps(p[4])}"
                for p in products
            ]
            
            self.vector_store.add_texts(
                documents,
                metadatas=[{
                    "sku_id": p[0],
                    "name": p[1],
                    "specs": p[2],
                    "urls": p[4],
                    "images": p[5],
                    "relations": p[6]
                } for p in products]
            )
            print(f"Indexed {offset + batch_size}/{total} products")
    
    def search_similar(self, query: str, k: int = 10):
        return self.vector_store.similarity_search(query, k=k)
```

#### 2.3 LLM Setup (Ollama + Llama2)

```bash
# Pull model (one-time, ~4GB download)
ollama pull llama2:7b

# Optional: Pull multilingual model
ollama pull mistral:7b

# Test model
curl http://localhost:11434/api/generate -d '{
  "model": "llama2:7b",
  "prompt": "What is an industrial PLC?",
  "stream": false
}'
```

```python
# engine/llm/model_config.py
from langchain.llms import Ollama
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

class IndustrialLLM:
    def __init__(self):
        self.callbacks = CallbackManager([StreamingStdOutCallbackHandler()])
        self.llm = Ollama(
            model="llama2:7b",
            base_url="http://localhost:11434",
            callbacks=self.callbacks,
            temperature=0.2,  # Low temperature for factual recommendations
            top_p=0.8
        )
    
    def generate_recommendation(self, context: str, user_query: str) -> str:
        """Generate recommendation with context from scraped data"""
        prompt = f"""
You are an expert industrial automation consultant. Based ONLY on the following 
product data, recommend solutions for this query.

PRODUCT DATA:
{context}

USER QUERY: {user_query}

RESPONSE REQUIREMENTS:
1. Only recommend products from the data provided
2. Include SKU IDs and manufacturer names
3. Provide confidence score (0.0-1.0)
4. Explain technical reasoning
5. Suggest complementary products
6. Provide datasheet links

RECOMMENDATION:
"""
        return self.llm(prompt)
```

---

### PHASE 3: RAG (RETRIEVAL-AUGMENTED GENERATION) CHAIN (Days 5-6)

#### 3.1 RAG Pipeline Architecture

```python
# engine/rag/recommendation_chain.py
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.vectorstores import Milvus
from langchain.llms import Ollama
import json

class IndustrialRAGChain:
    def __init__(self):
        self.llm = Ollama(model="llama2:7b", base_url="http://localhost:11434")
        self.vector_store = Milvus(
            connection_args={"host": "localhost", "port": 19530},
            collection_name="industrial_products"
        )
        self.retriever = self.vector_store.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 15}  # Retrieve top 15 similar products
        )
    
    def create_recommendation_prompt(self) -> PromptTemplate:
        template = """
You are an industrial automation product recommendation expert. Your role is to 
provide accurate, technical recommendations based ONLY on the product data provided.

RETRIEVED PRODUCTS:
{context}

USER QUERY: {question}

RESPONSE FORMAT (JSON):
{{
  "primary_recommendation": {{
    "sku_id": "...",
    "product_name": "...",
    "manufacturer": "...",
    "reasoning": "Why this product fits the requirement",
    "confidence_score": 0.95,
    "datasheet_url": "...",
    "images": ["..."]
  }},
  "alternative_products": [
    {{"sku_id": "...", "reason": "..."}}
  ],
  "complementary_products": [
    {{"sku_id": "...", "category": "..."}}
  ],
  "system_architecture": "If multiple products needed, describe the complete system",
  "technical_specifications": "Key specs relevant to the query",
  "compliance_notes": "Certifications, safety ratings",
  "estimated_cost_range": "$XXX - $XXX",
  "next_steps": "Contact, quotation, or direct purchase"
}}

USER LANGUAGE: Detect from query and respond in same language (English/Arabic)

IMPORTANT:
- Every product reference must include a source
- Only use data from RETRIEVED PRODUCTS
- If no exact match, explain what you found closest and why
- Include confidence scores for all recommendations
- Provide datasheet links for technical validation

RESPONSE:
"""
        return PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )
    
    def get_recommendation(self, query: str) -> dict:
        """Main entry point for recommendations"""
        qa = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.retriever,
            prompt=self.create_recommendation_prompt(),
            return_source_documents=True
        )
        
        result = qa({"query": query})
        
        # Parse LLM response as JSON
        try:
            response_json = json.loads(result["result"])
        except:
            response_json = {"raw_response": result["result"]}
        
        # Attach source documents
        response_json["sources"] = [
            {
                "sku_id": doc.metadata.get("sku_id"),
                "name": doc.metadata.get("name"),
                "datasheet": doc.metadata.get("urls")
            }
            for doc in result["source_documents"]
        ]
        
        return response_json
```

#### 3.2 Multimodal Input Processing (Image/PDF/Datasheet Search)

```python
# engine/multimodal/document_processor.py
import pytesseract
from PIL import Image
import PyPDF2
from transformers import BlipProcessor, BlipForConditionalGeneration
import numpy as np

class DocumentProcessor:
    def __init__(self):
        # For image understanding
        self.processor = BlipProcessor.from_pretrained(
            "Salesforce/blip-image-captioning-large"
        )
        self.model = BlipForConditionalGeneration.from_pretrained(
            "Salesforce/blip-image-captioning-large"
        )
    
    def process_image(self, image_path: str) -> str:
        """Extract text and visual information from image"""
        image = Image.open(image_path)
        
        # OCR text extraction
        extracted_text = pytesseract.image_to_string(image)
        
        # Image understanding (what product is this?)
        inputs = self.processor(image, return_tensors="pt")
        out = self.model.generate(**inputs, max_length=100)
        caption = self.processor.decode(out[0], skip_special_tokens=True)
        
        return f"Image: {caption}\nExtracted Text: {extracted_text}"
    
    def process_pdf(self, pdf_path: str) -> str:
        """Extract product info from datasheet PDF"""
        with open(pdf_path, 'rb') as f:
            reader = PyPDF2.PdfReader(f)
            text = "\n".join([page.extract_text() for page in reader.pages[:3]])
        return text
    
    def process_sheet(self, sheet_path: str) -> list:
        """Parse CSV/Excel specifications"""
        import pandas as pd
        df = pd.read_csv(sheet_path) if sheet_path.endswith('.csv') else pd.read_excel(sheet_path)
        return df.to_dict('records')
    
    def find_product_match(self, processed_content: str) -> dict:
        """Find matching products based on processed content"""
        from engine.rag.recommendation_chain import IndustrialRAGChain
        rag = IndustrialRAGChain()
        return rag.get_recommendation(processed_content)
```

---

### PHASE 4: WEB API & INTEGRATION (Days 6-7)

#### 4.1 FastAPI Server

```python
# api/server.py
from fastapi import FastAPI, File, UploadFile, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import json
import asyncio
from engine.rag.recommendation_chain import IndustrialRAGChain
from engine.multimodal.document_processor import DocumentProcessor
from engine.purchasing.journey_handler import PurchasingJourneyHandler

app = FastAPI(title="Industrial Automation Recommendation API", version="1.0.0")

# CORS for WooCommerce integration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://alsakronline.com", "https://*.alsakronline.com"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize engines
rag_chain = IndustrialRAGChain()
doc_processor = DocumentProcessor()
journey_handler = PurchasingJourneyHandler()

# Models
class RecommendationRequest(BaseModel):
    query: str
    language: str = "en"  # 'en' or 'ar'
    user_id: str = None
    session_id: str = None

class ContactDetails(BaseModel):
    name: str
    email: str
    company: str
    phone: str
    industry: str
    country: str

class QuotationRequest(BaseModel):
    sku_ids: list
    quantity: dict
    delivery_country: str
    contact: ContactDetails

# Endpoints
@app.post("/api/v1/recommend")
async def get_recommendation(req: RecommendationRequest):
    """Main recommendation endpoint"""
    try:
        # Translate query to English if Arabic
        if req.language == "ar":
            from engine.translation.translator import translate_to_english
            req.query = translate_to_english(req.query)
        
        # Get recommendation
        result = rag_chain.get_recommendation(req.query)
        
        # Translate response back to Arabic if needed
        if req.language == "ar":
            result = translate_response_to_arabic(result)
        
        # Track in CRM
        if req.user_id:
            journey_handler.track_interaction(req.user_id, req.query, result)
        
        return {
            "status": "success",
            "data": result,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.post("/api/v1/upload-document")
async def upload_document(
    file: UploadFile = File(...),
    document_type: str = "datasheet"  # 'image', 'pdf', 'sheet'
):
    """Handle image/PDF/sheet uploads"""
    try:
        contents = await file.read()
        temp_path = f"/tmp/{file.filename}"
        with open(temp_path, 'wb') as f:
            f.write(contents)
        
        if document_type == "image":
            content = doc_processor.process_image(temp_path)
        elif document_type == "pdf":
            content = doc_processor.process_pdf(temp_path)
        else:  # sheet
            content = doc_processor.process_sheet(temp_path)
        
        # Find matching products
        match_result = doc_processor.find_product_match(str(content))
        
        return {"status": "success", "matches": match_result}
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.post("/api/v1/contact-capture")
async def capture_contact(contact: ContactDetails):
    """Capture customer contact for CRM"""
    try:
        contact_id = journey_handler.save_contact(contact.dict())
        # Trigger n8n workflow for lead qualification
        await journey_handler.trigger_lead_workflow(contact_id)
        
        return {"status": "success", "contact_id": contact_id}
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.post("/api/v1/quotation-request")
async def request_quotation(req: QuotationRequest):
    """Create quotation request"""
    try:
        quotation_id = journey_handler.create_quotation(
            req.sku_ids,
            req.quantity,
            req.delivery_country,
            req.contact.dict()
        )
        
        # Send to manufacturer/sales team
        await journey_handler.send_quotation_request(quotation_id)
        
        return {
            "status": "success",
            "quotation_id": quotation_id,
            "message": "Your quotation request has been sent to our sales team"
        }
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.websocket("/ws/chat/{session_id}")
async def websocket_chat(websocket: WebSocket, session_id: str):
    """WebSocket for real-time chat"""
    await websocket.accept()
    try:
        while True:
            data = await websocket.receive_json()
            
            # Get recommendation
            result = rag_chain.get_recommendation(data.get("query"))
            
            # Send back in real-time
            await websocket.send_json({
                "status": "response",
                "recommendation": result
            })
    except Exception as e:
        await websocket.send_json({"status": "error", "message": str(e)})
    finally:
        await websocket.close()

@app.get("/api/v1/health")
async def health_check():
    """System health check"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "components": {
            "llm": "operational",
            "vector_db": "operational",
            "postgres": "operational"
        }
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

#### 4.2 WooCommerce Integration

```php
// wp-content/plugins/industrial-recommendation-engine/plugin.php
<?php
/**
 * Plugin Name: Industrial Automation Recommendation Engine
 * Description: AI-powered product recommendations for industrial automation
 * Version: 1.0.0
 */

// Enqueue chat widget
add_action('wp_footer', function() {
    ?>
    <div id="recommendation-widget"></div>
    <script>
    const API_BASE = "https://your-api.alsakronline.com/api/v1";
    
    window.RecommendationWidget = {
        init: function() {
            this.renderChatUI();
            this.setupWebSocket();
        },
        
        renderChatUI: function() {
            const widget = document.getElementById('recommendation-widget');
            widget.innerHTML = `
                <div class="rec-chat-container">
                    <div class="rec-chat-header">
                        <h3>Product Recommendation Assistant</h3>
                        <p class="rec-lang-toggle">
                            <span class="lang-en active">English</span> | 
                            <span class="lang-ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</span>
                        </p>
                    </div>
                    <div class="rec-chat-body" id="chat-messages"></div>
                    <div class="rec-chat-footer">
                        <textarea id="query-input" placeholder="Describe your automation need..."></textarea>
                        <button id="send-btn">Send</button>
                        <button id="upload-btn">ðŸ“Ž Upload (PDF/Image)</button>
                    </div>
                </div>
            `;
            
            this.attachEventHandlers();
        },
        
        attachEventHandlers: function() {
            document.getElementById('send-btn').addEventListener('click', () => this.sendQuery());
            document.getElementById('query-input').addEventListener('keypress', (e) => {
                if(e.key === 'Enter') this.sendQuery();
            });
            document.getElementById('upload-btn').addEventListener('click', () => this.openUploadDialog());
        },
        
        sendQuery: function() {
            const query = document.getElementById('query-input').value;
            const language = document.querySelector('.rec-lang-toggle .active').classList.contains('lang-ar') ? 'ar' : 'en';
            
            fetch(API_BASE + '/recommend', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify({query, language, user_id: this.getUserId()})
            })
            .then(r => r.json())
            .then(data => this.displayRecommendation(data.data))
            .catch(e => console.error(e));
        },
        
        displayRecommendation: function(rec) {
            const chatBody = document.getElementById('chat-messages');
            const html = `
                <div class="recommendation-card">
                    <h4>${rec.primary_recommendation.product_name}</h4>
                    <p>SKU: ${rec.primary_recommendation.sku_id}</p>
                    <p>Confidence: ${(rec.primary_recommendation.confidence_score * 100).toFixed(0)}%</p>
                    <p>${rec.primary_recommendation.reasoning}</p>
                    <button onclick="addToCart('${rec.primary_recommendation.sku_id}')">Add to Cart</button>
                    <button onclick="requestQuotation()">Request Quotation</button>
                </div>
            `;
            chatBody.innerHTML += html;
        },
        
        getUserId: function() {
            return wp.data.select('wc/store/customer').getCustomer().id || 'anonymous';
        }
    };
    
    document.addEventListener('DOMContentLoaded', () => RecommendationWidget.init());
    </script>
    <style>
    .rec-chat-container {
        position: fixed;
        bottom: 20px;
        right: 20px;
        width: 400px;
        height: 600px;
        background: white;
        border-radius: 10px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        display: flex;
        flex-direction: column;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto;
        z-index: 9999;
    }
    .rec-chat-header {
        background: #2c3e50;
        color: white;
        padding: 15px;
        border-radius: 10px 10px 0 0;
    }
    .rec-chat-body {
        flex: 1;
        overflow-y: auto;
        padding: 15px;
    }
    .rec-chat-footer {
        border-top: 1px solid #eee;
        padding: 15px;
        display: flex;
        gap: 10px;
    }
    .rec-chat-footer textarea {
        flex: 1;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 5px;
        resize: none;
    }
    .rec-chat-footer button {
        padding: 10px 15px;
        background: #0066cc;
        color: white;
        border: none;
        border-radius: 5px;
        cursor: pointer;
    }
    .recommendation-card {
        background: #f8f9fa;
        border-left: 4px solid #0066cc;
        padding: 12px;
        margin-bottom: 10px;
        border-radius: 5px;
    }
    </style>
    <?php
});

// Sync products with recommendation engine
add_action('woocommerce_update_product', function($product_id) {
    $product = wc_get_product($product_id);
    $payload = [
        'sku_id' => $product->get_sku(),
        'product_name' => $product->get_name(),
        'price' => $product->get_price(),
        'description' => $product->get_description(),
        'images' => $product->get_gallery_image_ids(),
        'categories' => wp_get_post_terms($product_id, 'product_cat', ['fields' => 'names'])
    ];
    
    // Send to recommendation API
    wp_remote_post('https://your-api.alsakronline.com/api/v1/sync-product', [
        'body' => json_encode($payload),
        'headers' => ['Content-Type' => 'application/json']
    ]);
});
?>
```

---

### PHASE 5: PURCHASING JOURNEY & CRM (Days 7)

#### 5.1 Purchase Journey Handler with n8n Integration

```python
# engine/purchasing/journey_handler.py
import psycopg2
import requests
import json
from datetime import datetime
from typing import dict, list

class PurchasingJourneyHandler:
    def __init__(self):
        self.db_conn = psycopg2.connect(
            "dbname=automation_engine user=postgres password=secure_password"
        )
        self.n8n_webhook = "https://your-n8n-instance.com/webhook/lead-handler"
    
    def save_contact(self, contact_data: dict) -> str:
        """Save contact to CRM database"""
        cursor = self.db_conn.cursor()
        cursor.execute("""
            INSERT INTO crm_contacts 
            (name, email, company, phone, industry, country, created_at)
            VALUES (%s, %s, %s, %s, %s, %s, NOW())
            RETURNING contact_id
        """, (
            contact_data['name'],
            contact_data['email'],
            contact_data['company'],
            contact_data['phone'],
            contact_data['industry'],
            contact_data['country']
        ))
        contact_id = cursor.fetchone()[0]
        self.db_conn.commit()
        return contact_id
    
    def track_interaction(self, user_id: str, query: str, recommendation: dict):
        """Track user queries and recommendations for analytics"""
        cursor = self.db_conn.cursor()
        cursor.execute("""
            INSERT INTO interaction_log
            (user_id, query, recommended_sku, confidence_score, timestamp)
            VALUES (%s, %s, %s, %s, NOW())
        """, (
            user_id,
            query,
            recommendation.get('primary_recommendation', {}).get('sku_id'),
            recommendation.get('primary_recommendation', {}).get('confidence_score')
        ))
        self.db_conn.commit()
    
    def create_quotation(self, sku_ids: list, quantity: dict, 
                         delivery_country: str, contact: dict) -> str:
        """Create quotation request"""
        cursor = self.db_conn.cursor()
        
        # Insert quotation
        cursor.execute("""
            INSERT INTO quotations
            (contact_id, sku_list, quantities, delivery_country, status, created_at)
            VALUES (%s, %s, %s, %s, 'pending', NOW())
            RETURNING quotation_id
        """, (
            self.save_contact(contact),
            json.dumps(sku_ids),
            json.dumps(quantity),
            delivery_country
        ))
        quotation_id = cursor.fetchone()[0]
        self.db_conn.commit()
        
        # Calculate total and compile quotation
        total_price = self._calculate_quotation_price(sku_ids, quantity)
        
        return quotation_id
    
    async def send_quotation_request(self, quotation_id: str):
        """Send quotation to sales team and manufacturers via n8n"""
        cursor = self.db_conn.cursor()
        cursor.execute("""
            SELECT q.*, c.email, c.company FROM quotations q
            JOIN crm_contacts c ON q.contact_id = c.contact_id
            WHERE q.quotation_id = %s
        """, (quotation_id,))
        
        quotation = cursor.fetchone()
        
        # Trigger n8n workflow
        response = requests.post(self.n8n_webhook, json={
            "quotation_id": quotation_id,
            "customer_email": quotation[1],
            "customer_company": quotation[2],
            "sku_list": json.loads(quotation[3]),
            "status": "new_quotation"
        })
        
        if response.status_code == 200:
            cursor.execute("""
                UPDATE quotations SET status = 'sent_to_sales'
                WHERE quotation_id = %s
            """, (quotation_id,))
            self.db_conn.commit()
    
    def get_recommended_upsells(self, primary_sku: str) -> list:
        """Get complementary products for upselling"""
        cursor = self.db_conn.cursor()
        cursor.execute("""
            SELECT p.sku_id, p.product_name, p.pricing,
                   (p.relationships->>'often_paired_with')::text[] as complements
            FROM products p
            WHERE p.sku_id = %s
        """, (primary_sku,))
        
        product = cursor.fetchone()
        if not product or not product[3]:
            return []
        
        complements = product[3]
        cursor.execute("""
            SELECT sku_id, product_name, pricing
            FROM products WHERE sku_id = ANY(%s)
            LIMIT 5
        """, (complements,))
        
        return [
            {
                "sku_id": row[0],
                "name": row[1],
                "price": row[2],
                "reason": "Often paired with primary selection"
            }
            for row in cursor.fetchall()
        ]
    
    def _calculate_quotation_price(self, sku_ids: list, quantities: dict) -> float:
        """Calculate total price for quotation"""
        cursor = self.db_conn.cursor()
        total = 0
        
        for sku_id in sku_ids:
            cursor.execute(
                "SELECT pricing->>'wholesale_usd' FROM products WHERE sku_id = %s",
                (sku_id,)
            )
            price_row = cursor.fetchone()
            if price_row:
                price = float(price_row[0])
                qty = quantities.get(sku_id, 1)
                total += price * qty
        
        return total
```

#### 5.2 n8n Workflow for Lead Qualification

```json
{
  "name": "Lead Qualification & Quotation Pipeline",
  "nodes": [
    {
      "type": "webhook",
      "name": "Incoming Lead",
      "parameters": {
        "path": "lead-handler",
        "method": "POST"
      }
    },
    {
      "type": "switch",
      "name": "Check Industry",
      "parameters": {
        "cases": [
          {
            "condition": "industry == 'Automotive'",
            "output": 1
          },
          {
            "condition": "industry == 'Food & Beverage'",
            "output": 2
          },
          {
            "condition": "industry == 'Pharma'",
            "output": 3
          }
        ]
      }
    },
    {
      "type": "slack",
      "name": "Notify Sales - Automotive Lead",
      "parameters": {
        "channel": "#automotive-leads",
        "message": "New lead from {{company}} - Contact: {{name}} ({{email}})"
      }
    },
    {
      "type": "email",
      "name": "Send Welcome Email",
      "parameters": {
        "to": "{{email}}",
        "subject": "Your Personalized Industrial Automation Quote",
        "template": "quotation_welcome"
      }
    },
    {
      "type": "hubspot",
      "name": "Create HubSpot Contact",
      "parameters": {
        "email": "{{email}}",
        "company": "{{company}}",
        "industry": "{{industry}}"
      }
    },
    {
      "type": "response",
      "name": "Return Success",
      "parameters": {
        "body": "{\"status\": \"success\", \"message\": \"Lead processed\"}"
      }
    }
  ]
}
```

---

### PHASE 6: DEPLOYMENT & MONITORING (Day 8 onwards)

#### 6.1 Docker Deployment Script

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    postgresql-client \
    tesseract-ocr \
    libsm6 libxext6 libxrender-dev \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Expose API port
EXPOSE 8000

# Start server
CMD ["python", "-m", "uvicorn", "api.server:app", "--host", "0.0.0.0", "--port", "8000"]
```

```bash
# deployment/deploy.sh
#!/bin/bash

echo "ðŸš€ Deploying Industrial Automation Engine..."

# Stop existing containers
docker-compose -f deployment/docker-compose.yml down

# Build and start
docker-compose -f deployment/docker-compose.yml up -d

# Wait for services to be healthy
sleep 10

# Run database migrations
docker exec automation-engine python -m alembic upgrade head

# Index products
docker exec automation-engine python -c "
from engine.embeddings.vector_indexer import ProductVectorIndexer
indexer = ProductVectorIndexer()
indexer.index_products_batch()
print('âœ… Products indexed successfully')
"

# Verify deployment
curl http://localhost:8000/api/v1/health

echo "âœ… Deployment complete!"
```

#### 6.2 Monitoring & Analytics

```python
# monitoring/analytics.py
from prometheus_client import Counter, Histogram, Gauge
import logging

# Metrics
recommendation_counter = Counter(
    'recommendations_total',
    'Total recommendations generated',
    ['industry', 'confidence_level']
)

query_latency = Histogram(
    'query_latency_seconds',
    'Recommendation query latency',
    buckets=(0.1, 0.5, 1, 2, 5)
)

active_users = Gauge(
    'active_users',
    'Number of active users'
)

vector_db_performance = Gauge(
    'vector_search_latency_ms',
    'Vector database search latency'
)

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def log_recommendation(industry, confidence):
    recommendation_counter.labels(
        industry=industry,
        confidence_level='high' if confidence > 0.8 else 'medium' if confidence > 0.6 else 'low'
    ).inc()
```

---

## PART 3: DATA MODEL & SCHEMA

### 3.1 PostgreSQL Schema

```sql
-- Products Table (100K+ records)
CREATE TABLE products (
    sku_id VARCHAR(50) PRIMARY KEY,
    product_name VARCHAR(500),
    manufacturer VARCHAR(100),
    categories TEXT[],
    industry_use TEXT[],
    specifications JSONB,
    embedding_text TEXT,
    datasheet_url VARCHAR(500),
    datasheet_file VARCHAR(500),
    images TEXT[],
    pricing JSONB,
    relationships JSONB,
    last_updated TIMESTAMP DEFAULT NOW(),
    confidence_score FLOAT,
    source VARCHAR(100),
    language VARCHAR(10) DEFAULT 'en',
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_sku_id ON products(sku_id);
CREATE INDEX idx_manufacturer ON products(manufacturer);
CREATE INDEX idx_categories ON products USING GIN(categories);
CREATE INDEX idx_specifications ON products USING GIN(specifications);

-- CRM Contacts Table
CREATE TABLE crm_contacts (
    contact_id SERIAL PRIMARY KEY,
    name VARCHAR(255),
    email VARCHAR(255) UNIQUE,
    company VARCHAR(255),
    phone VARCHAR(20),
    industry VARCHAR(100),
    country VARCHAR(100),
    preferences JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Quotations Table
CREATE TABLE quotations (
    quotation_id SERIAL PRIMARY KEY,
    contact_id INTEGER REFERENCES crm_contacts(contact_id),
    sku_list JSONB,
    quantities JSONB,
    delivery_country VARCHAR(100),
    status VARCHAR(50),
    total_price DECIMAL(12, 2),
    created_at TIMESTAMP DEFAULT NOW(),
    expires_at TIMESTAMP DEFAULT NOW() + INTERVAL '30 days'
);

-- Interaction Log (Analytics)
CREATE TABLE interaction_log (
    interaction_id SERIAL PRIMARY KEY,
    user_id VARCHAR(255),
    query TEXT,
    recommended_sku VARCHAR(50),
    confidence_score FLOAT,
    response_time_ms INTEGER,
    timestamp TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_user_id ON interaction_log(user_id);
CREATE INDEX idx_timestamp ON interaction_log(timestamp);
```

---

## PART 4: READY-MADE TOOLS & THIRD-PARTY INTEGRATIONS

| Layer | Component | Tool | Integration |
|-------|-----------|------|-------------|
| **Data Ingestion** | Web Scraping | Scrapy + Selenium | Custom schedulers |
| | CSV/JSON Import | Pandas + SQLAlchemy | Batch import scripts |
| **Vector Search** | Embedding Model | Sentence-Transformers | HuggingFace Hub |
| | Vector DB | Milvus | Docker container |
| **LLM** | Model Serving | Ollama | Docker + API |
| | Model Fine-tuning | PEFT + LoRA | Optional upgrade |
| **Chat Interface** | Widget | Botpress | WooCommerce plugin |
| | Real-time | Socket.io | FastAPI WebSocket |
| **CRM/Workflow** | Automation | n8n | Self-hosted |
| | Email | Mailgun/SendGrid | API integration |
| **Analytics** | Monitoring | Prometheus + Grafana | Docker stack |
| | Privacy Analytics | Matomo | Self-hosted |

---

## PART 5: DETAILED DATA SCRAPING STRATEGY

### 5.1 Manufacturer Scraping Plan

```python
# tools/scrapers/config.py
SCRAPING_CONFIG = {
    "ABB": {
        "base_url": "https://new.abb.com/products",
        "products_path": "//article[@class='product-item']",
        "fields": {
            "name": ".product-name::text",
            "sku": ".product-sku::text",
            "specs": ".specifications::text",
            "datasheet": "a[contains(@href, 'pdf')]::attr(href)",
            "image": ".product-image::attr(src)",
            "price": ".price::text"
        },
        "scrape_frequency": "weekly"
    },
    "SICK": {
        "api_endpoint": "https://api.sick.com/catalog/v1/products",
        "auth_token": "${SICK_API_TOKEN}",
        "batch_size": 100,
        "scrape_frequency": "bi-weekly"
    },
    "Siemens": {
        "configurator_api": "https://www.siemens.com/automation/api/v1/products",
        "categories": ["SIMATIC", "SINUMERIK", "SIMOTION", "SITOP"],
        "scrape_frequency": "monthly"
    }
}

class ManufacturerScraper:
    def scrape_abb_products(self):
        """Scrape ABB catalog with pagination"""
        driver = webdriver.Chrome()
        all_products = []
        page = 1
        
        while page < 100:  # ABB has ~2000+ products across pages
            url = f"https://new.abb.com/products?page={page}"
            driver.get(url)
            
            # Scroll and wait for lazy loading
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(3)
            
            products = driver.find_elements(By.CSS_SELECTOR, "article.product-item")
            
            for product in products:
                try:
                    data = {
                        "manufacturer": "ABB",
                        "product_name": product.find_element(By.CSS_SELECTOR, ".product-name").text,
                        "sku": product.find_element(By.CSS_SELECTOR, ".product-sku").text,
                        "specifications": {
                            "raw_text": product.find_element(By.CSS_SELECTOR, ".specs").text
                        },
                        "datasheet_url": product.find_element(By.CSS_SELECTOR, "a[href*='pdf']").get_attribute("href"),
                        "images": [img.get_attribute("src") for img in product.find_elements(By.TAG_NAME, "img")],
                        "source": "abb_catalog_2025"
                    }
                    all_products.append(data)
                except:
                    continue
            
            page += 1
        
        return all_products
```

### 5.2 Data Validation & Enrichment

```python
# tools/data_validation.py
from jsonschema import validate, ValidationError

PRODUCT_SCHEMA = {
    "type": "object",
    "properties": {
        "sku_id": {"type": "string"},
        "product_name": {"type": "string"},
        "manufacturer": {"type": "string"},
        "specifications": {"type": "object"},
        "datasheet_url": {"type": "string", "format": "uri"},
        "images": {"type": "array"}
    },
    "required": ["sku_id", "product_name", "manufacturer"]
}

class DataValidator:
    def validate_and_enrich(self, products: list) -> list:
        """Validate and enrich product data"""
        enriched = []
        
        for product in products:
            try:
                validate(instance=product, schema=PRODUCT_SCHEMA)
                
                # Enrich with embeddings
                product['embedding_text'] = self._create_embedding_text(product)
                product['categories'] = self._infer_categories(product)
                product['confidence_score'] = 0.95
                
                enriched.append(product)
            except ValidationError as e:
                logger.warning(f"Invalid product: {e}")
                continue
        
        return enriched
    
    def _create_embedding_text(self, product: dict) -> str:
        """Create dense text for embeddings"""
        return f"""
        {product['product_name']}
        Manufacturer: {product['manufacturer']}
        Specifications: {json.dumps(product.get('specifications', {}))}
        Description: {product.get('description', '')}
        """
```

---

## PART 6: RAG vs FINE-TUNING DECISION MATRIX

### Decision: Hybrid Approach (RAG + Optional Fine-tuning)

| Aspect | RAG | Fine-tuning | Recommendation |
|--------|-----|-------------|-----------------|
| **Data Freshness** | Real-time | Epoch-based | RAG (weekly updates) |
| **Accuracy** | 85-92% | 88-95% | RAG initially, FT later |
| **Cost** | Low (embeddings only) | High (GPU time) | Start RAG, upgrade to FT |
| **Speed** | <5s (good) | <2s (excellent) | RAG meets requirements |
| **Scalability** | 100K+ docs | Limited by dataset size | RAG preferred |
| **Maintenance** | Low | High | RAG maintenance simpler |

### Implementation Timeline:
- **MVP (Week 1)**: RAG with Llama2-7B
- **v1.1 (Month 2)**: Optional LoRA fine-tuning on top-50 manufacturers
- **v2.0 (Month 3)**: Full model fine-tuning if performance gains justify cost

---

## PART 7: MULTILINGUAL & TONE ADAPTATION

### 7.1 Language & Tone Configuration

```python
# engine/translation/multilingual.py
from transformers import MarianMTModel, MarianTokenizer

LANGUAGE_CONFIG = {
    "en": {
        "tone": "technical",
        "templates": {
            "recommendation": "Based on your requirement for {requirement}, we recommend {product}...",
            "technical": "The {specification} meets your {constraint} requirement..."
        }
    },
    "ar": {
        "tone": "technical_formal",
        "templates": {
            "recommendation": "Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…ØªØ·Ù„Ø¨Ùƒ Ù„Ù€ {requirement}ØŒ Ù†ÙˆØµÙŠ Ø¨Ù€ {product}...",
            "technical": "{specification} ÙŠÙˆÙÙŠ Ø¨Ù…ØªØ·Ù„Ø¨ {constraint} Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ..."
        }
    }
}

class MultilingualAdapter:
    def __init__(self):
        self.en_ar_model = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-en-ar")
        self.en_ar_tokenizer = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-en-ar")
    
    def translate_to_arabic(self, text: str) -> str:
        """Translate English recommendation to Arabic"""
        inputs = self.en_ar_tokenizer(text, return_tensors="pt")
        translated = self.en_ar_model.generate(**inputs)
        return self.en_ar_tokenizer.decode(translated[0], skip_special_tokens=True)
    
    def adapt_tone(self, response: dict, language: str, user_type: str) -> dict:
        """Adapt response tone based on user type"""
        if user_type == "engineer":
            # Keep technical jargon
            response['tone'] = 'technical'
        elif user_type == "procurement":
            # Emphasize price and lead time
            response['tone'] = 'commercial'
        else:
            # Simplified explanation
            response['tone'] = 'educational'
        
        return response
```

---

## PART 8: SECURITY & COMPLIANCE

### 8.1 GDPR Compliance Checklist

- **Data Minimization**: Only collect name, email, company, phone, industry
- **Right to Erasure**: Implement contact deletion endpoint
- **Data Portability**: Export interaction history as JSON
- **Consent Management**: Capture opt-in for email communications
- **Data Encryption**: TLS for all API traffic, encrypted database connections
- **Privacy Policy**: Update WooCommerce privacy policy to include recommendation system

### 8.2 Implementation

```python
# security/gdpr_handler.py
class GDPRHandler:
    def delete_contact(self, contact_id: str):
        """Implement right to erasure"""
        cursor = self.db.cursor()
        
        # Delete all personal data
        cursor.execute("DELETE FROM crm_contacts WHERE contact_id = %s", (contact_id,))
        cursor.execute("DELETE FROM quotations WHERE contact_id = %s", (contact_id,))
        cursor.execute("DELETE FROM interaction_log WHERE user_id = %s", (contact_id,))
        
        self.db.commit()
        logger.info(f"Contact {contact_id} deleted per GDPR request")
    
    def export_user_data(self, user_id: str) -> dict:
        """Export all user data for portability"""
        cursor = self.db.cursor()
        
        cursor.execute("SELECT * FROM crm_contacts WHERE contact_id = %s", (user_id,))
        contact_data = cursor.fetchone()
        
        cursor.execute("SELECT * FROM quotations WHERE contact_id = %s", (user_id,))
        quotation_data = cursor.fetchall()
        
        cursor.execute("SELECT * FROM interaction_log WHERE user_id = %s", (user_id,))
        interaction_data = cursor.fetchall()
        
        return {
            "contact": contact_data,
            "quotations": quotation_data,
            "interactions": interaction_data
        }
```

---

## QUICK START CHECKLIST

### Week 1 (MVP)
- [ ] Setup Docker & PostgreSQL on Hostinger
- [ ] Deploy Milvus vector database
- [ ] Deploy Ollama + Llama2-7B
- [ ] Build FastAPI server with `/recommend` endpoint
- [ ] Create WooCommerce chat widget
- [ ] Scrape 10K sample products from ABB & SICK
- [ ] Index products in Milvus
- [ ] Test end-to-end recommendation flow

### Week 2-4 (Production)
- [ ] Scale to 100K+ products
- [ ] Implement image/PDF upload & processing
- [ ] Integrate n8n purchasing workflows
- [ ] Add Arabic language support
- [ ] Setup Prometheus monitoring
- [ ] Load test (<5s response time)
- [ ] GDPR compliance audit
- [ ] Performance optimization

---

## FILES TO CREATE

1. `docker-compose.yml` - Service orchestration
2. `requirements.txt` - Python dependencies
3. `api/server.py` - FastAPI server
4. `engine/rag/recommendation_chain.py` - RAG orchestration
5. `engine/embeddings/vector_indexer.py` - Vector indexing
6. `engine/multimodal/document_processor.py` - Image/PDF handling
7. `engine/purchasing/journey_handler.py` - CRM workflow
8. `tools/scrapers/industrial_scraper.py` - Web scraping
9. `wp-content/plugins/industrial-recommendation-engine/plugin.php` - WooCommerce integration
10. Database migration scripts (Alembic)

---

**End of Architecture Document**
